#!/usr/bin/env python3
"""å¾®ä¿¡å…¬ä¼—å·å‘å¸ƒå·¥å…· - å°†è®ºæ–‡å‘å¸ƒä¸ºå…¬ä¼—å·å›¾æ–‡æ–‡ç« .

Usage:
    # 1) ä¸Šä¼ å°é¢å›¾
    python scripts/publish.py upload-cover path/to/cover.jpg

    # 2) ä» daily pipeline è¾“å‡ºå‘å¸ƒ
    python scripts/publish.py publish --cover MEDIA_ID --input data/index/YYYY-MM-DD/daily_topics.json

    # 3) å‘å¸ƒå¹¶è‡ªåŠ¨æ¨é€
    python scripts/publish.py publish --cover MEDIA_ID --auto
"""

from __future__ import annotations

import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path

import yaml

# Add project root to import path.
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.models import Paper
from src.publisher import PublishError, PublisherConfig, WeChatPublisher

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


def load_config() -> dict:
    """Load config YAML."""
    config_path = Path(__file__).parent.parent / "config" / "config.yaml"
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def create_publisher(config: dict) -> WeChatPublisher:
    """Create WeChat publisher instance."""
    pub_config = config.get("publisher", {})
    wechat = pub_config.get("wechat", {})

    if not wechat.get("app_id") or not wechat.get("app_secret"):
        print("âŒ é”™è¯¯: è¯·åœ¨ config/config.yaml ä¸­é…ç½® publisher.wechat.app_id å’Œ app_secret")
        sys.exit(1)

    return WeChatPublisher(
        PublisherConfig(
            enabled=True,
            app_id=wechat["app_id"],
            app_secret=wechat["app_secret"],
            auto_publish=pub_config.get("auto_publish", False),
            include_abstract=pub_config.get("include_abstract", True),
            include_authors=pub_config.get("include_authors", True),
            article_author=pub_config.get("author", "arXiv Paper Bot"),
            default_cover=wechat.get("default_cover", ""),
        )
    )


def _parse_datetime(value: str | None) -> datetime:
    if not value:
        return datetime.now()
    try:
        return datetime.fromisoformat(value.replace("Z", "+00:00"))
    except ValueError:
        return datetime.now()


def _flatten_daily_topics(payload: dict) -> list[dict]:
    rows: list[dict] = []
    topics = payload.get("topics") or []
    for topic in topics:
        for paper in topic.get("papers") or []:
            rows.append(
                {
                    "arxiv_id": paper.get("paper_id", ""),
                    "title": paper.get("title", ""),
                    "abstract": paper.get("abstract", ""),
                    "authors": paper.get("authors", []),
                    "primary_category": paper.get("primary_category", ""),
                    "categories": paper.get("categories", []),
                    "pdf_url": paper.get("pdf_url", ""),
                    "entry_url": paper.get("entry_url", ""),
                    "published": paper.get("published"),
                    "updated": paper.get("updated"),
                    "score": paper.get("relevance", 0),
                    "matched_keywords": paper.get("recall_hits", []),
                }
            )
    return rows


def load_papers(input_path: str) -> list[Paper]:
    """Load papers from legacy list JSON or daily_topics grouped JSON."""
    with open(input_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    if isinstance(data, list):
        rows = data
    elif isinstance(data, dict) and isinstance(data.get("topics"), list):
        rows = _flatten_daily_topics(data)
    else:
        raise ValueError("Unsupported JSON format. Expected papers list or daily_topics JSON")

    papers: list[Paper] = []
    for item in rows:
        papers.append(
            Paper(
                arxiv_id=item.get("arxiv_id", ""),
                title=item.get("title", ""),
                abstract=item.get("abstract", ""),
                authors=item.get("authors", []),
                primary_category=item.get("primary_category", ""),
                categories=item.get("categories", []),
                pdf_url=item.get("pdf_url", ""),
                entry_url=item.get("entry_url", ""),
                published=_parse_datetime(item.get("published")),
                updated=_parse_datetime(item.get("updated")),
                score=item.get("score", 0),
                matched_keywords=item.get("matched_keywords", []),
            )
        )

    return papers


def _find_default_input_path(root: Path) -> Path | None:
    daily_files = sorted((root / "data" / "index").glob("*/daily_topics.json"), reverse=True)
    if daily_files:
        return daily_files[0]

    legacy = root / "data" / "papers.json"
    if legacy.exists():
        return legacy

    return None


def cmd_upload_cover(args, config):
    """Upload a cover image and print media id."""
    publisher = create_publisher(config)
    print(f"ğŸ“¤ ä¸Šä¼ å°é¢å›¾ç‰‡: {args.image_path}")

    try:
        media_id = publisher.upload_image(args.image_path)
        print("\nâœ… ä¸Šä¼ æˆåŠŸ!")
        print(f"   media_id: {media_id}")
        print("\nğŸ’¡ å¯å°†æ­¤ media_id å†™å…¥ config/config.yaml:")
        print("   publisher:")
        print("     wechat:")
        print(f'       default_cover: "{media_id}"')
    except PublishError as e:
        print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
        sys.exit(1)


def cmd_publish(args, config):
    """Publish papers to WeChat."""
    publisher = create_publisher(config)
    project_root = Path(__file__).parent.parent

    if args.input:
        input_path = Path(args.input)
    else:
        input_path = _find_default_input_path(project_root)

    if not input_path or not input_path.exists():
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°å¯å‘å¸ƒè®ºæ–‡æ–‡ä»¶")
        print("   å…ˆè¿è¡Œæ—¥æ›´ä¸»æµç¨‹ï¼Œä¾‹å¦‚:")
        print("   python -m src.pipeline.run_daily --config config/config.yaml --day YYYY-MM-DD")
        print("   æˆ–ä½¿ç”¨ --input æ˜¾å¼æŒ‡å®š JSON æ–‡ä»¶")
        sys.exit(1)

    print(f"ğŸ“– ä»æ–‡ä»¶åŠ è½½è®ºæ–‡: {input_path}")

    try:
        papers = load_papers(str(input_path))
    except Exception as exc:
        print(f"âŒ åŠ è½½è®ºæ–‡å¤±è´¥: {exc}")
        sys.exit(1)

    if not papers:
        print("âŒ é”™è¯¯: æ²¡æœ‰å¯å‘å¸ƒçš„è®ºæ–‡")
        sys.exit(1)

    papers = papers[: args.top_k]
    print(f"ğŸ“š å‡†å¤‡å‘å¸ƒ {len(papers)} ç¯‡è®ºæ–‡")

    thumb_media_id = args.cover or config.get("publisher", {}).get("wechat", {}).get("default_cover")
    if not thumb_media_id:
        print("âŒ é”™è¯¯: ç¼ºå°‘å°é¢å›¾ media_id")
        print("   è¯·ä½¿ç”¨ --cover å‚æ•°æŒ‡å®šï¼Œæˆ–åœ¨é…ç½®ä¸­è®¾ç½® default_cover")
        print("   ä¸Šä¼ å°é¢å›¾: python scripts/publish.py upload-cover path/to/cover.jpg")
        sys.exit(1)

    try:
        if args.auto:
            publisher.config.auto_publish = True
            print("ğŸš€ è‡ªåŠ¨å‘å¸ƒæ¨¡å¼å·²å¯ç”¨")

        result = publisher.publish_papers(papers, thumb_media_id=thumb_media_id)

        print("\nâœ… æ“ä½œæˆåŠŸ!")
        print(f"   è‰ç¨¿ media_id: {result['media_id']}")

        if result.get("publish_id"):
            print(f"   å‘å¸ƒä»»åŠ¡ ID: {result['publish_id']}")
            print(f"   çŠ¶æ€: {result['status']}")
            print("\nğŸ’¡ å‘å¸ƒéœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·åœ¨å…¬ä¼—å·åå°æŸ¥çœ‹å‘å¸ƒçŠ¶æ€")
        else:
            print("   çŠ¶æ€: å·²ä¿å­˜åˆ°è‰ç¨¿ç®±")
            print("\nğŸ’¡ è¯·å‰å¾€å…¬ä¼—å·åå° -> è‰ç¨¿ç®± æŸ¥çœ‹å¹¶æ‰‹åŠ¨å‘å¸ƒ")

    except PublishError as e:
        print(f"âŒ å‘å¸ƒå¤±è´¥: {e}")
        sys.exit(1)


def cmd_status(args, config):
    """Query publish task status."""
    publisher = create_publisher(config)

    try:
        status = publisher.get_publish_status(args.publish_id)
        print("ğŸ“Š å‘å¸ƒçŠ¶æ€:")
        print(json.dumps(status, indent=2, ensure_ascii=False))
    except PublishError as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        description="å¾®ä¿¡å…¬ä¼—å·å‘å¸ƒå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    upload_parser = subparsers.add_parser("upload-cover", help="ä¸Šä¼ å°é¢å›¾ç‰‡")
    upload_parser.add_argument("image_path", help="å›¾ç‰‡æ–‡ä»¶è·¯å¾„")

    publish_parser = subparsers.add_parser("publish", help="å‘å¸ƒè®ºæ–‡åˆ°å…¬ä¼—å·")
    publish_parser.add_argument("--cover", help="å°é¢å›¾ media_id")
    publish_parser.add_argument("--input", "-i", help="è®ºæ–‡ JSON æ–‡ä»¶è·¯å¾„")
    publish_parser.add_argument("--top-k", type=int, default=10, help="å‘å¸ƒè®ºæ–‡æ•°é‡ (é»˜è®¤: 10)")
    publish_parser.add_argument("--auto", action="store_true", help="è‡ªåŠ¨å‘å¸ƒ (ä¸åªæ˜¯ä¿å­˜è‰ç¨¿)")

    status_parser = subparsers.add_parser("status", help="æŸ¥è¯¢å‘å¸ƒçŠ¶æ€")
    status_parser.add_argument("publish_id", help="å‘å¸ƒä»»åŠ¡ ID")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(0)

    config = load_config()

    if args.command == "upload-cover":
        cmd_upload_cover(args, config)
    elif args.command == "publish":
        cmd_publish(args, config)
    elif args.command == "status":
        cmd_status(args, config)


if __name__ == "__main__":
    main()
