"""[Archived] Legacy experiment utility. Not part of the supported workflow."""

"""
GPT-4 (120B) vs DeepSeek R1 æ€ç»´é“¾å¯¹æ¯”æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
1. é…ç½® .env æ–‡ä»¶: OPENROUTER_API_KEY=your_key
2. é…ç½® OpenRouter éšç§è®¾ç½®: https://openrouter.ai/settings/privacy
   - é€‰æ‹© "Allow free models to be trained on my data"
3. è¿è¡Œ: python compare_reasoning_example.py

æ”¯æŒä¸¤ç§è°ƒç”¨æ–¹å¼:
- USE_OPENAI_CLIENT = True: ä½¿ç”¨ OpenAI SDK (æ¨è)
- USE_OPENAI_CLIENT = False: ä½¿ç”¨ requests ç›´æ¥è°ƒç”¨

æ³¨æ„: å¦‚æœé‡åˆ° 404 é”™è¯¯ "No endpoints found matching your data policy"ï¼Œ
è¯·è®¿é—® https://openrouter.ai/settings/privacy é…ç½®éšç§ç­–ç•¥ã€‚
"""

import json
import time

import requests

from api_request import BASE_URL, OPENROUTER_API_KEY

# é€‰æ‹©è°ƒç”¨æ–¹å¼
USE_OPENAI_CLIENT = True  # æ”¹ä¸º False ä½¿ç”¨ requests æ–¹å¼

# å°è¯•å¯¼å…¥ OpenAI SDK
if USE_OPENAI_CLIENT:
    try:
        from openai import OpenAI
    except ImportError:
        print("âš ï¸  æœªå®‰è£… openai åº“ï¼Œå°†ä½¿ç”¨ requests æ–¹å¼")
        print("   å®‰è£…å‘½ä»¤: pip install openai")
        USE_OPENAI_CLIENT = False

# æµ‹è¯•é—®é¢˜é›†
PROBLEMS = [
    {
        "name": "é€’æ¨åºåˆ—ä¸æé™",
        "problem": """Consider a sequence {a_n} defined by:
- a_1 = 1, a_2 = 2
- For n â‰¥ 3: a_n = a_{n-1} + a_{n-2} + n

Find a_{10} and determine if lim_{nâ†’âˆ} (a_n / a_{n-1}) exists.""",
    },
    {
        "name": "ç»„åˆæ¦‚ç‡",
        "problem": """A fair die is rolled repeatedly. Let X be the number of rolls until the sum first exceeds 20.
(a) What is E[X]?
(b) What is P(X = 6)?""",
    },
    {
        "name": "æ•°è®ºæ–¹ç¨‹",
        "problem": """Find all positive integer solutions (x, y, z) to: xÂ³ + yÂ³ + zÂ³ = 42
Explain your approach.""",
    },
    {
        "name": "å‡ ä½•ä¼˜åŒ–",
        "problem": """A rectangle has perimeter 100 cm. If length increases by 20% and width decreases by 10%, area increases by 8 cmÂ².
Find the original dimensions.""",
    },
    {
        "name": "å¤æ•°æ–¹ç¨‹",
        "problem": """Solve for all complex numbers z: zâ´ + 4zÂ³ + 6zÂ² + 4z + 5 = 0
Express solutions in a + bi form.""",
    },
    {
        "name": "å¾®ç§¯åˆ†åº”ç”¨",
        "problem": """Find the volume of the solid formed by rotating the region bounded by y = xÂ², y = 0, and x = 2 around the y-axis.
Show all steps.""",
    },
    {
        "name": "çº¿æ€§ä»£æ•°",
        "problem": """Given matrix A = [[2, 1], [1, 2]], find A^10 without direct multiplication.
Use eigenvalue decomposition.""",
    },
    {
        "name": "å›¾è®º",
        "problem": """A complete graph K_n has n vertices where every pair is connected. How many spanning trees does K_5 have?
Use Cayley's formula or matrix-tree theorem.""",
    },
]


def call_model_openai_sdk(model_id: str, problem: str) -> dict:
    """ä½¿ç”¨ OpenAI SDK è°ƒç”¨ (æ¨èæ–¹å¼)"""
    client = OpenAI(
        base_url=BASE_URL,
        api_key=OPENROUTER_API_KEY,
        default_headers={
            "HTTP-Referer": "https://github.com",  # å¿…éœ€ï¼Œç”¨äºéšç§ç­–ç•¥
            "X-Title": "Math Reasoning Test",  # å¯é€‰ï¼Œç”¨äºæ ‡è¯†
        },
    )

    try:
        completion = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": "system", "content": "You are a mathematician. Solve step by step."},
                {"role": "user", "content": problem},
            ],
            max_tokens=16384,
            temperature=0.3,
        )

        message = completion.choices[0].message

        return {
            "content": message.content or "",
            "reasoning": getattr(message, "reasoning_content", "") or "",
            "usage": {
                "prompt_tokens": completion.usage.prompt_tokens,
                "completion_tokens": completion.usage.completion_tokens,
                "total_tokens": completion.usage.total_tokens,
            },
            "model": completion.model,
        }

    except Exception as e:
        return {"error": f"OpenAI SDK Error: {str(e)}"}


def call_model_requests(model_id: str, problem: str) -> dict:
    """ä½¿ç”¨ requests ç›´æ¥è°ƒç”¨"""
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://github.com",  # å¿…éœ€ï¼Œç”¨äºéšç§ç­–ç•¥
        "X-Title": "Math Reasoning Test",  # å¯é€‰ï¼Œç”¨äºæ ‡è¯†
    }

    payload = {
        "model": model_id,
        "messages": [
            {"role": "system", "content": "You are a mathematician. Solve step by step."},
            {"role": "user", "content": problem},
        ],
        "max_tokens": 16384,
        "temperature": 0.3,
    }

    try:
        response = requests.post(
            f"{BASE_URL}/chat/completions", headers=headers, json=payload, timeout=180
        )

        if response.status_code != 200:
            return {"error": f"HTTP {response.status_code}: {response.text}"}

        result = response.json()
        message = result["choices"][0]["message"]

        return {
            "content": message.get("content", ""),
            "reasoning": message.get("reasoning_content", ""),
            "usage": result.get("usage", {}),
            "model": result.get("model", model_id),
        }

    except Exception as e:
        return {"error": f"Requests Error: {str(e)}"}


def call_model(model_id: str, problem: str) -> dict:
    """è°ƒç”¨æ¨¡å‹ (è‡ªåŠ¨é€‰æ‹©è°ƒç”¨æ–¹å¼)"""
    if not OPENROUTER_API_KEY:
        raise ValueError("è¯·è®¾ç½® OPENROUTER_API_KEY")

    if USE_OPENAI_CLIENT:
        return call_model_openai_sdk(model_id, problem)
    else:
        return call_model_requests(model_id, problem)


def test_single_problem(problem_data: dict, models: list[str]):
    """æµ‹è¯•å•ä¸ªé—®é¢˜"""
    print("\n" + "=" * 100)
    print(f"é—®é¢˜: {problem_data['name']}")
    print("=" * 100)
    print(f"\n{problem_data['problem']}\n")

    results = {}

    for model_id in models:
        model_name = "GPT-4 (120B)" if "gpt" in model_id else "DeepSeek R1"
        print(f"\n{'â”€' * 100}")
        print(f"æ¨¡å‹: {model_name} ({model_id})")
        print("â”€" * 100)

        start = time.time()
        response = call_model(model_id, problem_data["problem"])
        elapsed = time.time() - start

        if "error" in response:
            print(f"\nâŒ é”™è¯¯: {response['error']}")
            continue

        results[model_id] = {"response": response, "time": elapsed}

        # æ‰“å°å®Œæ•´è¾“å‡º
        print(f"\nâ±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
        print(f"ğŸ“Š Token: {response['usage']}")

        if response["reasoning"]:
            print(f"\nğŸ§  æ€ç»´é“¾ ({len(response['reasoning'])} å­—ç¬¦):")
            print("â”€" * 100)
            print(response["reasoning"])

        print(f"\nğŸ’¬ æœ€ç»ˆå›å¤ ({len(response['content'])} å­—ç¬¦):")
        print("â”€" * 100)
        print(response["content"])

        time.sleep(2)  # é¿å…é¢‘ç¹è°ƒç”¨

    return results


def batch_test(problems: list[dict], models: list[str], output_file: str = "results.json"):
    """æ‰¹é‡æµ‹è¯•æ‰€æœ‰é—®é¢˜"""
    all_results = []

    for i, problem_data in enumerate(problems, 1):
        print(f"\n\n{'#' * 100}")
        print(f"# æµ‹è¯• {i}/{len(problems)}")
        print(f"{'#' * 100}")

        results = test_single_problem(problem_data, models)

        all_results.append(
            {
                "problem": problem_data["name"],
                "question": problem_data["problem"],
                "results": {
                    model_id: {
                        "time": data["time"],
                        "content": data["response"]["content"],
                        "reasoning": data["response"]["reasoning"],
                        "usage": data["response"]["usage"],
                    }
                    for model_id, data in results.items()
                },
            }
        )

    # ä¿å­˜ç»“æœ
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)

    print(f"\n\n{'=' * 100}")
    print(f"âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print("=" * 100)

    # æ‰“å°ç»Ÿè®¡
    print("\nğŸ“Š ç»Ÿè®¡æ‘˜è¦:")
    for model_id in models:
        model_name = "GPT-4 (120B)" if "gpt" in model_id else "DeepSeek R1"
        total_time = sum(
            r["results"].get(model_id, {}).get("time", 0) for r in all_results
        )
        total_tokens = sum(
            r["results"].get(model_id, {}).get("usage", {}).get("total_tokens", 0)
            for r in all_results
        )
        print(f"\n{model_name}:")
        print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"  æ€»Token: {total_tokens}")
        print(f"  å¹³å‡è€—æ—¶: {total_time / len(problems):.2f}ç§’/é¢˜")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 100)
    print("GPT-4 (120B) vs DeepSeek R1 - æ€ç»´é“¾å¯¹æ¯”æµ‹è¯•")
    print("=" * 100)

    # æ˜¾ç¤ºè°ƒç”¨æ–¹å¼
    call_method = "OpenAI SDK" if USE_OPENAI_CLIENT else "Requests"
    print(f"\nğŸ“¡ è°ƒç”¨æ–¹å¼: {call_method}")
    print(f"ğŸ”‘ API Key: {'å·²é…ç½®' if OPENROUTER_API_KEY else 'âŒ æœªé…ç½®'}")

    # å¯ç”¨çš„å…è´¹æ¨¡å‹
    models = [
        "openai/gpt-oss-120b:free",  # GPT-4 120B
        "tngtech/deepseek-r1t2-chimera:free",
        "nex-agi/deepseek-v3.1-nex-n1:free", 
        "tngtech/deepseek-r1t-chimera:free",
        "z-ai/glm-4.5-air:free", # DeepSeek V3.1 (æ”¯æŒæ€ç»´é“¾)
    ]

    print(f"\nğŸ“‹ ä½¿ç”¨æ¨¡å‹:")
    print(f"  1. {models[0]} (GPT-4 120B)")
    print(f"  2. {models[1]} (DeepSeek R1 - æ”¯æŒæ€ç»´é“¾)")
    print(f"\nâš ï¸  å¦‚æœé‡åˆ° 404 é”™è¯¯ï¼Œè¯·è®¿é—®:")
    print(f"     https://openrouter.ai/settings/privacy")
    print(f"     é€‰æ‹© 'Allow free models to be trained on my data'")

    print(f"\nå…±æœ‰ {len(PROBLEMS)} ä¸ªæµ‹è¯•é—®é¢˜")
    print("\né€‰é¡¹:")
    print("  1. æµ‹è¯•å•ä¸ªé—®é¢˜")
    print("  2. æ‰¹é‡æµ‹è¯•æ‰€æœ‰é—®é¢˜")
    print("  3. æµ‹è¯•å‰ N ä¸ªé—®é¢˜")
    print("  4. å¿«é€Ÿç¤ºä¾‹ (å¯¹æ¯”ä¸¤ç§è°ƒç”¨æ–¹å¼)")

    try:
        choice = input("\nè¯·é€‰æ‹© (1/2/3/4): ").strip()

        if choice == "1":
            print("\nå¯ç”¨é—®é¢˜:")
            for i, p in enumerate(PROBLEMS, 1):
                print(f"  {i}. {p['name']}")
            idx = int(input(f"\né€‰æ‹©é—®é¢˜ (1-{len(PROBLEMS)}): ")) - 1
            test_single_problem(PROBLEMS[idx], models)

        elif choice == "2":
            batch_test(PROBLEMS, models)

        elif choice == "3":
            n = int(input(f"æµ‹è¯•å‰å‡ ä¸ªé—®é¢˜ (1-{len(PROBLEMS)}): "))
            batch_test(PROBLEMS[:n], models, f"results_top{n}.json")

        elif choice == "4":
            demo_api_methods()

        else:
            print("æ— æ•ˆé€‰æ‹©")

    except (ValueError, KeyboardInterrupt, IndexError) as e:
        print(f"\næ“ä½œå–æ¶ˆæˆ–å‡ºé”™: {e}")


def demo_api_methods():
    """æ¼”ç¤ºä¸åŒçš„ API è°ƒç”¨æ–¹å¼"""
    print("\n" + "=" * 100)
    print("API è°ƒç”¨æ–¹å¼æ¼”ç¤º")
    print("=" * 100)

    test_problem = "Solve: x^2 + 5x + 6 = 0"
    print(f"\næµ‹è¯•é—®é¢˜: {test_problem}\n")

    # æ–¹æ³•1: OpenAI SDK è°ƒç”¨ GPT-4
    if USE_OPENAI_CLIENT:
        print("\n" + "â”€" * 100)
        print("æ–¹æ³•1: OpenAI SDK è°ƒç”¨ GPT-4 (120B)")
        print("â”€" * 100)

        try:
            client = OpenAI(
                base_url=BASE_URL,
                api_key=OPENROUTER_API_KEY,
                default_headers={
                    "HTTP-Referer": "https://github.com",
                    "X-Title": "Math Reasoning Test",
                },
            )

            completion = client.chat.completions.create(
                model="openai/gpt-oss-120b:free",
                messages=[
                    {"role": "system", "content": "You are a helpful math tutor."},
                    {"role": "user", "content": test_problem},
                ],
                max_tokens=500,
                temperature=0.3,
            )

            message = completion.choices[0].message
            print(f"\nğŸ’¬ å›å¤:\n{message.content}")
            print(f"\nğŸ“Š Token: {completion.usage.total_tokens}")
            print(f"ğŸ”§ æ¨¡å‹: {completion.model}")

        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

    # æ–¹æ³•2: requests è°ƒç”¨ GPT-4
    print("\n" + "â”€" * 100)
    print("æ–¹æ³•2: requests è°ƒç”¨ GPT-4 (120B)")
    print("â”€" * 100)

    try:
        headers = {
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com",
            "X-Title": "Math Reasoning Test",
        }

        payload = {
            "model": "openai/gpt-oss-120b:free",
            "messages": [
                {"role": "system", "content": "You are a helpful math tutor."},
                {"role": "user", "content": test_problem},
            ],
            "max_tokens": 500,
            "temperature": 0.3,
        }

        response = requests.post(
            f"{BASE_URL}/chat/completions",
            headers=headers,
            json=payload,
            timeout=60,
        )

        result = response.json()
        message = result["choices"][0]["message"]

        print(f"\nğŸ’¬ å›å¤:\n{message['content']}")
        print(f"\nğŸ“Š Token: {result['usage']['total_tokens']}")
        print(f"ğŸ”§ æ¨¡å‹: {result['model']}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

    # æ–¹æ³•3: OpenAI SDK è°ƒç”¨ DeepSeek R1 (å¸¦æ€ç»´é“¾)
    if USE_OPENAI_CLIENT:
        print("\n" + "â”€" * 100)
        print("æ–¹æ³•3: OpenAI SDK è°ƒç”¨ DeepSeek R1 (å¸¦æ€ç»´é“¾)")
        print("â”€" * 100)

        try:
            client = OpenAI(base_url=BASE_URL, api_key=OPENROUTER_API_KEY)

            completion = client.chat.completions.create(
                model="deepseek/deepseek-r1-0528:free",
                messages=[
                    {"role": "system", "content": "You are a helpful math tutor."},
                    {"role": "user", "content": test_problem},
                ],
                max_tokens=1000,
                temperature=0.3,
            )

            message = completion.choices[0].message

            # è·å–æ€ç»´é“¾
            reasoning = getattr(message, "reasoning_content", None)
            if reasoning:
                print(f"\nğŸ§  æ€ç»´é“¾ ({len(reasoning)} å­—ç¬¦):\n{reasoning}")

            print(f"\nğŸ’¬ æœ€ç»ˆå›å¤:\n{message.content}")
            print(f"\nğŸ“Š Token: {completion.usage.total_tokens}")

        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

    print("\n" + "=" * 100)
    print("âœ… æ¼”ç¤ºå®Œæˆ")
    print("=" * 100)
    print("\næç¤º:")
    print("  - OpenAI SDK æ–¹å¼ä»£ç æ›´ç®€æ´ï¼Œæ¨èä½¿ç”¨")
    print("  - requests æ–¹å¼æ— éœ€é¢å¤–ä¾èµ–")
    print("  - DeepSeek R1 æ”¯æŒæŸ¥çœ‹å®Œæ•´æ€ç»´é“¾")
    print(f"  - å½“å‰ä½¿ç”¨: {'OpenAI SDK' if USE_OPENAI_CLIENT else 'requests'}")
    print(f"  - åˆ‡æ¢æ–¹å¼: ç¼–è¾‘æ–‡ä»¶ç¬¬ 23 è¡Œ USE_OPENAI_CLIENT")


if __name__ == "__main__":
    main()
