# arXiv Paper Bot - Tests

This directory contains unit tests for all major components of the arXiv Paper Bot.

## ğŸ§ª Running Tests

### Run all tests:
```bash
python run_tests.py
```

### Run with verbose output:
```bash
python run_tests.py -v
```

### Run specific test file:
```bash
python -m unittest tests.test_filter
```

### Run specific test class:
```bash
python -m unittest tests.test_filter.TestPaperFilter
```

### Run specific test method:
```bash
python -m unittest tests.test_filter.TestPaperFilter.test_keyword_matching
```

## ğŸ“ Test Structure

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_models.py      # Tests for data models (Paper, Config classes)
â”œâ”€â”€ test_filter.py      # Tests for keyword filtering and ranking
â”œâ”€â”€ test_storage.py     # Tests for JSON/CSV storage
â”œâ”€â”€ test_notifier.py    # Tests for notification push logic
â””â”€â”€ fixtures/           # Test data (if needed)
```

## ğŸ¯ Test Coverage

### `test_models.py`
- Paper model creation and conversion
- Configuration model defaults
- Dictionary and CSV row conversion
- Data validation

### `test_filter.py`
- Keyword matching in titles and abstracts
- Multi-priority keyword weighting
- Score calculation and ranking
- Min score threshold filtering
- Top-k limiting
- Statistics generation

### `test_storage.py`
- JSON file saving and loading
- CSV file saving and loading
- Append mode functionality
- Duplicate removal
- File creation in non-existent directories

### `test_notifier.py`
- Message formatting utility
- Builder validation forå„æ¸ é“é…ç½®
- é£ä¹¦/Telegram/å¾®ä¿¡å…¬ä¼—å·æ¨é€è°ƒç”¨ï¼ˆé€šè¿‡ `requests` mockï¼‰

## âœ… Expected Results

All tests should pass:
```
Ran X tests in Y.YYYs

OK
```

If any tests fail, check:
1. Dependencies are installed (`pip install -r requirements.txt`)
2. Python version is 3.8+ (`python --version`)
3. Working directory is project root

## ğŸ” Writing New Tests

When adding new features, add corresponding tests:

1. Create test class inheriting from `unittest.TestCase`
2. Add `setUp()` method for test data
3. Write test methods starting with `test_`
4. Use descriptive test names
5. Add assertions to verify behavior

Example:
```python
class TestNewFeature(unittest.TestCase):
    def setUp(self):
        self.data = create_test_data()

    def test_feature_works(self):
        result = my_function(self.data)
        self.assertEqual(result, expected_value)
```

## ğŸ“Š Test Guidelines

- **Keep tests independent**: Each test should run standalone
- **Use temporary files**: Clean up after tests (see `test_storage.py`)
- **Test edge cases**: Empty input, None values, large datasets
- **Assert clearly**: Use specific assertions (`assertEqual`, `assertIn`, etc.)
- **Document tests**: Add docstrings explaining what is tested
